import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np

# Gemini ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
try:
    import google.generativeai as genai
    gemini_installed = True
except ImportError:
    gemini_installed = False

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Zone 2 Precision Lab", layout="wide")

# --- [Gemini API ì„¤ì •: ëª¨ë¸ í˜¸í™˜ì„± ê°•í™”] ---
gemini_ready = False
available_models = []
if gemini_installed:
    api_key = st.secrets.get("GEMINI_API_KEY")
    if api_key:
        try:
            genai.configure(api_key=api_key)
            # 1ë‹¨ê³„: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ë””ë²„ê¹…ìš©)
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            
            # 2ë‹¨ê³„: ê°€ì¥ ì•ˆì •ì ì¸ gemini-pro ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ
            target_model = 'models/gemini-pro' if 'models/gemini-pro' in available_models else available_models[0]
            
            ai_model = genai.GenerativeModel(target_model)
            gemini_ready = True
        except Exception as e:
            st.error(f"Gemini ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

# ìŠ¤íƒ€ì¼ ì •ì˜
st.markdown("""
    <style>
    .main { background-color: #09090b; }
    div[data-testid="stMetricValue"] { color: #fafafa; font-size: 1.8rem; font-weight: 700; }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] {
        height: 45px; background-color: #18181b; border-radius: 8px;
        border: 1px solid #27272a; color: #a1a1aa; padding: 0px 25px;
    }
    .stTabs [aria-selected="true"] { background-color: #27272a; color: #fff; border: 1px solid #3f3f46; }
    .stInfo, .stSuccess, .stWarning, .stError { border-radius: 12px; border: 1px solid #27272a; background-color: #18181b; }
    .section-title { color: #a1a1aa; font-size: 0.8rem; font-weight: 600; text-transform: uppercase; margin-bottom: 12px; letter-spacing: 0.05em; }
    </style>
    """, unsafe_allow_html=True)

# 2. ë°ì´í„° ì—°ê²° ë° ì „ì²˜ë¦¬ (ìƒëµ ì—†ì´ ì „ì²´ í¬í•¨)
conn = st.connection("gsheets", type=GSheetsConnection)
df = conn.read(ttl=0)

if not df.empty:
    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce').dt.date
    df = df.dropna(subset=['ë‚ ì§œ'])
    for col in ['íšŒì°¨', 'ì›œì—…íŒŒì›Œ', 'ë³¸í›ˆë ¨íŒŒì›Œ', 'ì¿¨ë‹¤ìš´íŒŒì›Œ', 'ë³¸í›ˆë ¨ì‹œê°„']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

# 3. ì‚¬ì´ë“œë°” (History)
with st.sidebar:
    st.markdown("### ğŸ” History")
    if not df.empty:
        sessions = sorted(df["íšŒì°¨"].unique().tolist(), reverse=True)
        selected_session = st.selectbox("ì¡°íšŒí•  íšŒì°¨", sessions, index=0)
        s_data = df[df["íšŒì°¨"] == selected_session].iloc[0]
    else: s_data = None

# 4. ë©”ì¸ í™”ë©´ êµ¬ì„±
tab_entry, tab_analysis, tab_trends = st.tabs(["ğŸ†• New Session", "ğŸ¯ Analysis", "ğŸ“ˆ Trends"])

# --- [TAB 1: ë°ì´í„° ì…ë ¥ (ë™ì  UI)] ---
with tab_entry:
    st.markdown('<p class="section-title">Step 1: Training Setup</p>', unsafe_allow_html=True)
    c1, c2, c3 = st.columns([1, 1, 2])
    f_date = c1.date_input("ë‚ ì§œ", value=pd.to_datetime(s_data['ë‚ ì§œ']) if s_data is not None else pd.Timestamp.now().date())
    f_session = c2.number_input("íšŒì°¨", value=int(df["íšŒì°¨"].max() + 1) if not df.empty else 1, step=1)
    f_duration = c3.slider("ë³¸ í›ˆë ¨ ì‹œê°„(ë¶„) ì„¤ì •", 15, 180, int(s_data['ë³¸í›ˆë ¨ì‹œê°„']) if s_data is not None else 60, step=5)
    
    p1, p2, p3 = st.columns(3)
    f_wp = p1.number_input("ì›œì—… íŒŒì›Œ (10ë¶„)", value=int(s_data['ì›œì—…íŒŒì›Œ']) if s_data is not None else 100)
    f_mp = p2.number_input("ë³¸í›ˆë ¨ íŒŒì›Œ", value=int(s_data['ë³¸í›ˆë ¨íŒŒì›Œ']) if s_data is not None else 140)
    f_cp = p3.number_input("ì¿¨ë‹¤ìš´ íŒŒì›Œ (5ë¶„)", value=int(s_data['ì¿¨ë‹¤ìš´íŒŒì›Œ']) if s_data is not None else 90)

    st.divider()
    st.markdown(f'<p class="section-title">Step 2: Heart Rate Entry ({f_duration + 15}m Full Course)</p>', unsafe_allow_html=True)

    total_points = ( (10 + f_duration + 5) // 5 ) + 1
    existing_hrs = str(s_data['ì „ì²´ì‹¬ë°•ë°ì´í„°']).split(",") if s_data is not None else []
    
    hr_inputs = []
    h_cols = st.columns(4)
    for i in range(total_points):
        t = i * 5
        if t <= 10: label = f"ğŸŸ¢ ì›œì—… {t}m"
        elif t <= 10 + f_duration: label = f"ğŸ”µ ë³¸í›ˆë ¨ {t}m"
        else: label = f"âšª ì¿¨ë‹¤ìš´ {t}m"
        try: def_val = int(float(existing_hrs[i].strip()))
        except: def_val = 130
        with h_cols[i % 4]:
            hr_val = st.number_input(label, value=def_val, key=f"hr_input_point_{i}", step=1)
            hr_inputs.append(str(int(hr_val)))

    if st.button("ğŸš€ SAVE TRAINING RECORD", width='stretch'):
        main_hrs = [int(x) for x in hr_inputs[2:-1]]
        mid = len(main_hrs) // 2
        if len(main_hrs) >= 2:
            f_ef = f_mp / np.mean(main_hrs[:mid])
            s_ef = f_mp / np.mean(main_hrs[mid:])
            f_dec = round(((f_ef - s_ef) / f_ef) * 100, 2)
        else: f_dec = 0
        new_row = {
            "ë‚ ì§œ": f_date.strftime("%Y-%m-%d"), "íšŒì°¨": int(f_session), 
            "ì›œì—…íŒŒì›Œ": int(f_wp), "ë³¸í›ˆë ¨íŒŒì›Œ": int(f_mp), "ì¿¨ë‹¤ìš´íŒŒì›Œ": int(f_cp), 
            "ë³¸í›ˆë ¨ì‹œê°„": int(f_duration), "ë””ì»¤í”Œë§(%)": f_dec, "ì „ì²´ì‹¬ë°•ë°ì´í„°": ", ".join(hr_inputs)
        }
        updated_df = pd.concat([df[df["íšŒì°¨"] != f_session], pd.DataFrame([new_row])], ignore_index=True).sort_values("íšŒì°¨")
        updated_df['ë‚ ì§œ'] = updated_df['ë‚ ì§œ'].astype(str)
        conn.update(data=updated_df)
        st.success("ë°ì´í„° ì €ì¥ ì„±ê³µ!")
        st.rerun()

# --- [TAB 2: ë¶„ì„ ë° Gemini ì±„íŒ…] ---
with tab_analysis:
    if not df.empty and s_data is not None:
        # ë°ì´í„° ìš”ì•½ (ë©”íŠ¸ë¦­/ê·¸ë˜í”„ ë¡œì§ ìœ ì§€)
        hr_array = [int(float(x.strip())) for x in str(s_data['ì „ì²´ì‹¬ë°•ë°ì´í„°']).split(",")]
        current_dec, current_p, current_dur = s_data['ë””ì»¤í”Œë§(%)'], int(s_data['ë³¸í›ˆë ¨íŒŒì›Œ']), int(s_data['ë³¸í›ˆë ¨ì‹œê°„'])
        
        m1, m2, m3 = st.columns(3)
        m1.metric("Target Power", f"{current_p}W")
        m2.metric("Decoupling", f"{current_dec}%")
        m3.metric("Volume", f"{current_dur}m")

        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        time_x = [i*5 for i in range(len(hr_array))]
        power_y = [current_p] * len(time_x) # ë‹¨ìˆœí™”ëœ íŒŒì›Œë¼ì¸
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        fig.add_trace(go.Scatter(x=time_x, y=power_y, name="Power", line=dict(color='#3b82f6', shape='hv')), secondary_y=False)
        fig.add_trace(go.Scatter(x=time_x, y=hr_array, name="HR", line=dict(color='#ef4444')), secondary_y=True)
        fig.update_layout(template="plotly_dark", height=400)
        st.plotly_chart(fig, width='stretch')

        st.divider()
        st.markdown("### ğŸ’¬ Chat with Gemini Coach")
        
        if not gemini_ready:
            st.error("Geminië¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            if available_models: st.write(f"ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸: {available_models}")
        else:
            if "messages" not in st.session_state: st.session_state.messages = []
            chat_container = st.container(height=350)
            with chat_container:
                for msg in st.session_state.messages:
                    with st.chat_message(msg["role"]): st.markdown(msg["content"])
            
            if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
                st.session_state.messages.append({"role": "user", "content": prompt})
                with chat_container:
                    with st.chat_message("user"): st.markdown(prompt)
                
                context = f"ì‚¬ì´í´ë§ ì½”ì¹˜ë¡œì„œ ë¶„ì„í•´ì¤˜. íŒŒì›Œ:{current_p}W, ë””ì»¤í”Œë§:{current_dec}%. ì§ˆë¬¸:{prompt}"
                with chat_container:
                    with st.chat_message("assistant"):
                        try:
                            response = ai_model.generate_content(context)
                            st.markdown(response.text)
                            st.session_state.messages.append({"role": "assistant", "content": response.text})
                        except Exception as e:
                            st.error(f"ì‘ë‹µ ì—ëŸ¬: {e}")
                            st.write(f"ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {ai_model.model_name}")

# --- [TAB 3: ì¥ê¸° íŠ¸ë Œë“œ] ---
with tab_trends:
    if not df.empty:
        st.info("íŠ¸ë Œë“œ ë¶„ì„ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
